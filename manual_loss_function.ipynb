{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWbZud0MaikZ7188wwtwFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkm4/Manual-loss-function/blob/main/manual_loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ctwskLp7RXe4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Softmax function\n"
      ],
      "metadata": {
        "id": "zHtMvNPaSTXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def daniel_softmax(logits_tensor,axis):\n",
        "  logits_tensor = logits_tensor - logits_tensor.max(axis = axis , keepdim = True).values\n",
        "  exp_tensor = torch.exp(logits_tensor)\n",
        "\n",
        "  denominator_tensor = torch.sum(exp_tensor,axis=axis,keepdim = True)\n",
        "\n",
        "  prob_tensor = exp_tensor/denominator_tensor\n",
        "  return prob_tensor"
      ],
      "metadata": {
        "id": "ZquC-lqlRhyb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_tensor = torch.Tensor([[1,0,3],\n",
        "                             [6,5,4],\n",
        "                             [2,9,0]])\n",
        "\n",
        "new_tensor = daniel_softmax(logits_tensor,1)\n",
        "print(f\"calculation of softmax by my function is : {new_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn6A6B0NRjth",
        "outputId": "f0d8a4e7-5713-4941-fa82-07e1a60efa56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calculation of softmax by my function is : tensor([[1.1420e-01, 4.2010e-02, 8.4379e-01],\n",
            "        [6.6524e-01, 2.4473e-01, 9.0031e-02],\n",
            "        [9.1094e-04, 9.9897e-01, 1.2328e-04]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mean Square Error(MSE)"
      ],
      "metadata": {
        "id": "OdUp89X5ShNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def daniel_msl(y_pred, y_truth):\n",
        "  loss_tensor = (y_pred - y_truth)**2\n",
        "  add_num = loss_tensor.mean()\n",
        "  #add_num = add_num/y_pred.shape[0]\n",
        "  return add_num"
      ],
      "metadata": {
        "id": "m87GPSNISFX1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tensor = torch.Tensor([[3],\n",
        "                            [2],\n",
        "                            [1]])\n",
        "\n",
        "truth_tensor = torch.Tensor([[3],\n",
        "                             [3],\n",
        "                             [3]])\n",
        "loss_fn = nn.MSELoss()\n",
        "loss_mean = loss_fn(pred_tensor, truth_tensor)\n",
        "\n",
        "test_loss = daniel_msl(pred_tensor,truth_tensor)\n",
        "print(f\"shape of the test_loss is: {test_loss.shape}\")\n",
        "print(f\"the loss of the model was: {test_loss}\")\n",
        "print(f\"the shape of the train_loss is: {loss_mean.shape}\")\n",
        "print(f\"the loss of the model using MSE was: {loss_mean}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkxUgC3wSHUI",
        "outputId": "da944951-3fd4-4e6b-a874-19596c983154"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of the test_loss is: torch.Size([])\n",
            "the loss of the model was: 1.6666666269302368\n",
            "the shape of the train_loss is: torch.Size([])\n",
            "the loss of the model using MSE was: 1.6666666269302368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross entropy loss"
      ],
      "metadata": {
        "id": "tYAO5Tr8SkeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def daniel_CEL(logits, y_truth):\n",
        "  loss_softmax = torch.softmax(logits, dim=1)\n",
        "  neg_log = -torch.log(loss_softmax)\n",
        "  row_tensor = torch.arange(len(logits))\n",
        "\n",
        "  output_tensor = neg_log[row_tensor, y_truth]\n",
        "  mean_tensor = torch.mean(output_tensor)\n",
        "\n",
        "  return mean_tensor"
      ],
      "metadata": {
        "id": "skYjiPZ6SLil"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_tensor = torch.Tensor([[2,0,1],\n",
        "                              [1,0,2],\n",
        "                              [2,1,0]])\n",
        "truth_logit = torch.tensor([2,0,1])\n",
        "\n",
        "\n",
        "CEL_tensor = daniel_CEL(logits_tensor,truth_logit)\n",
        "print(f\"calulation by manual function is: {CEL_tensor}\")\n",
        "\n",
        "\n",
        "#truth_logit = truth_logit.squeeze().type(torch.long)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "training_loss = loss_fn(logits_tensor, truth_logit)\n",
        "print(f\"calulation by CEL is: {training_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qJvUAS-SNYc",
        "outputId": "6622681c-7162-49ce-f6c8-aa934f412381"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calulation by manual function is: 1.4076060056686401\n",
            "calulation by CEL is: 1.4076060056686401\n"
          ]
        }
      ]
    }
  ]
}